{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db89d224",
   "metadata": {},
   "source": [
    "# Loan Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fce842",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cf2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# importing the warnings library\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9456bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set print options\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=100, precision=2)\n",
    "\n",
    "\n",
    "\n",
    "# setting the warnings library to ignore the warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde855d7",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb21f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226.  ,         nan,    35000.  , ...,         nan,         nan,     9452.96],\n",
       "       [57693261.  ,         nan,    30000.  , ...,         nan,         nan,     4679.7 ],\n",
       "       [59432726.  ,         nan,    15000.  , ...,         nan,         nan,     1969.83],\n",
       "       ...,\n",
       "       [50415990.  ,         nan,    10000.  , ...,         nan,         nan,     2185.64],\n",
       "       [46154151.  ,         nan,         nan, ...,         nan,         nan,     3199.4 ],\n",
       "       [66055249.  ,         nan,    10000.  , ...,         nan,         nan,      301.9 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the dataset\n",
    "\n",
    "data_raw = np.genfromtxt(\"loan-data.csv\",\n",
    "                           delimiter=\";\",\n",
    "                           skip_header=1,\n",
    "                           autostrip=True)\n",
    "\n",
    "\n",
    "#displaying the dataset\n",
    "\n",
    "data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78107bc0",
   "metadata": {},
   "source": [
    "### Checking the Data for Missing Values and Replacing Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae022a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the number of missing values in the dataset\n",
    "\n",
    "np.isnan(data_raw).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27636884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "            440.92,         nan,         nan,         nan,         nan,         nan,     3143.85])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the temporary fill value\n",
    "\n",
    "temp_fill = np.nanmax(data_raw) + 1\n",
    "\n",
    "\n",
    "# creating a temporary mean value across the columns to fill them later\n",
    "\n",
    "temp_mean = np.nanmean(data_raw, axis=0)\n",
    "\n",
    "\n",
    "# display the temporary mean\n",
    "\n",
    "temp_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16c51f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,         nan,     1000.  ,         nan,     1000.  ,         nan,        6.  ,\n",
       "              31.42,         nan,         nan,         nan,         nan,         nan,        0.  ],\n",
       "       [54015809.19,         nan,    15273.46,         nan,    15311.04,         nan,       16.62,\n",
       "             440.92,         nan,         nan,         nan,         nan,         nan,     3143.85],\n",
       "       [68616519.  ,         nan,    35000.  ,         nan,    35000.  ,         nan,       28.99,\n",
       "            1372.97,         nan,         nan,         nan,         nan,         nan,    41913.62]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a array containing the variables that will be used later\n",
    "\n",
    "temp_stats = np.array([np.nanmin(data_raw, axis=0),\n",
    "                       temp_mean,\n",
    "                       np.nanmax(data_raw, axis=0)])\n",
    "\n",
    "\n",
    "# displaying the temp stats variable\n",
    "\n",
    "temp_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c9181",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b4d4c",
   "metadata": {},
   "source": [
    "### Splitting the Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47853e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  5,  8,  9, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the columns in the data set where there are only strings\n",
    "\n",
    "column_strings = np.argwhere(np.isnan(temp_mean)).squeeze()\n",
    "\n",
    "\n",
    "# display the array containing the index of the columns containing strings\n",
    "\n",
    "column_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e164d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7, 13], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the columna in the data set where there are only integers\n",
    "\n",
    "column_numeric = np.argwhere(np.isnan(temp_mean)==False).squeeze()\n",
    "\n",
    "\n",
    "# display the array containing the index of the columns containing integers\n",
    "\n",
    "column_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18cd15c",
   "metadata": {},
   "source": [
    "### Re-importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d49af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "       ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "       ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "       ...,\n",
       "       ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "       ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "       ['Dec-15', 'Current', '36 months', ..., '',\n",
       "        'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the sub-dataset containing only the strings\n",
    "\n",
    "data_strings = np.genfromtxt(\"loan-data.csv\",\n",
    "                            delimiter=\";\",\n",
    "                            skip_header=1,\n",
    "                            autostrip=True,\n",
    "                            usecols=column_strings,\n",
    "                            dtype='str')\n",
    "\n",
    "# displaying the sub-dataset containing only strings\n",
    "\n",
    "data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb4ee080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226,    35000,    35000,       13,     1184,     9452],\n",
       "       [57693261,    30000,    30000, 68616520,      938,     4679],\n",
       "       [59432726,    15000,    15000, 68616520,      494,     1969],\n",
       "       ...,\n",
       "       [50415990,    10000,    10000, 68616520, 68616520,     2185],\n",
       "       [46154151, 68616520,    10000,       16,      354,     3199],\n",
       "       [66055249,    10000,    10000, 68616520,      309,      301]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the sub-set containig only the numeric\n",
    "\n",
    "data_numeric = np.genfromtxt(\"loan-data.csv\",\n",
    "                            delimiter=';',\n",
    "                            autostrip=True,\n",
    "                            usecols=column_numeric,\n",
    "                            skip_header=1,\n",
    "                            dtype='int',\n",
    "                            filling_values=temp_fill)\n",
    "\n",
    "\n",
    "# displaying the sub-dataset containing only numeric\n",
    "\n",
    "data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11ac6a",
   "metadata": {},
   "source": [
    "### Defining the Header Arrays for the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35ebf55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'issue_d', 'loan_amnt', 'loan_status', 'funded_amnt', 'term', 'int_rate',\n",
       "       'installment', 'grade', 'sub_grade', 'verification_status', 'url', 'addr_state',\n",
       "       'total_pymnt'], dtype='<U19')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the header row of the raw data\n",
    "\n",
    "header_full = np.genfromtxt('loan-data.csv',\n",
    "                           delimiter=';',\n",
    "                           skip_footer=data_raw.shape[0],\n",
    "                           dtype='str')\n",
    "\n",
    "\n",
    "# displaying the complete header array\n",
    "\n",
    "header_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c04544f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "        'addr_state'], dtype='<U19'),\n",
       " array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the headers for the strings and numeric sub-dataset\n",
    "\n",
    "header_strings, header_numeric = header_full[column_strings], header_full[column_numeric]\n",
    "\n",
    "\n",
    "# displaying the arrays for the strings and numeric headers\n",
    "\n",
    "header_strings, header_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a587a9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f62844",
   "metadata": {},
   "source": [
    "### Defining the Checkpoint Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729f1215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the checkpoint fuction\n",
    "\n",
    "def checkpoint(file_name, checkpoint_header, checkpoint_data):\n",
    "    np.savez(file_name, header=checkpoint_header, data=checkpoint_data)\n",
    "    checkpoint_variable = np.load(file_name + \".npz\")\n",
    "    return(checkpoint_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb112621",
   "metadata": {},
   "source": [
    "### Checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ab8d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up a checkpoint for all the string data\n",
    "\n",
    "checkpoint_split_string = checkpoint(\"checkpoint-split-string\",\n",
    "                             header_strings,\n",
    "                             data_strings)\n",
    "\n",
    "\n",
    "# checking if the data stored in the checkpoint is correct\n",
    "\n",
    "np.array_equal(checkpoint_split_string['data'], data_strings), np.array_equal(checkpoint_split_string['header'], header_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31158958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up a checkpoint for all the numeric data\n",
    "\n",
    "checkpoint_split_numeric = checkpoint(\"checkpoint-split-numeric\",\n",
    "                                     header_numeric,\n",
    "                                     data_numeric)\n",
    "\n",
    "\n",
    "# checking if the data stored in the checkpoint is correct\n",
    "\n",
    "np.array_equal(checkpoint_split_numeric['data'], data_numeric), np.array_equal(checkpoint_split_numeric['header'], header_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ccf25",
   "metadata": {},
   "source": [
    "## Transforming the String Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff24b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_d', 'loan_status', 'term', 'grade', 'sub_grade', 'verification_status', 'url',\n",
       "        'addr_state'], dtype='<U19'),\n",
       " array([['May-15', 'Current', '36 months', ..., 'Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "        ['', 'Current', '36 months', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "        ['Sep-15', 'Current', '36 months', ..., 'Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "        ...,\n",
       "        ['Jun-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "        ['Apr-15', 'Current', '36 months', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "        ['Dec-15', 'Current', '36 months', ..., '',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "       dtype='<U69'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the string headers and the string sub-dataset\n",
    "\n",
    "header_strings, data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c965209",
   "metadata": {},
   "source": [
    "### Issue Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e783636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr-15', 'Aug-15', 'Dec-15', 'Feb-15', 'Jan-15', 'Jul-15', 'Jun-15', 'Mar-15',\n",
       "       'May-15', 'Nov-15', 'Oct-15', 'Sep-15'], dtype='<U69')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the header name from issue_d to issue_date\n",
    "\n",
    "header_strings[0] = 'issue_date'\n",
    "\n",
    "\n",
    "# displaying all the unique values in the issue_date column\n",
    "\n",
    "np.unique(data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ce1b62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Apr', 'Aug', 'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep'],\n",
       "      dtype='<U69')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stripping away the year indicator from the dataset as the data is provided only for a single year\n",
    "\n",
    "data_strings[:,0] = np.chararray.strip(data_strings[:,0], \"-15\")\n",
    "\n",
    "\n",
    "# displaying all the unique values in the transformed issue_date column\n",
    "\n",
    "np.unique(data_strings[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40199f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a month array to transform the issue_data column, numeric\n",
    "\n",
    "months = np.array(['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "\n",
    "\n",
    "# assign corresponding numeric values to the months\n",
    "\n",
    "for i in range(len(np.unique(data_strings[:,0]))):\n",
    "    data_strings[:,0] = np.where(data_strings[:,0]==months[i],\n",
    "                                i,\n",
    "                                data_strings[:,0])\n",
    "\n",
    "\n",
    "# displaying all the sorted unique values in the transformed issue_date column\n",
    "\n",
    "np.sort(np.unique(data_strings[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8178e",
   "metadata": {},
   "source": [
    "### Loan Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d7903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'Charged Off', 'Current', 'Default', 'Fully Paid', 'In Grace Period', 'Issued',\n",
       "        'Late (16-30 days)', 'Late (31-120 days)'], dtype='<U69'),\n",
       " 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the unique values in the loan_status column and the number of unique values\n",
    "\n",
    "np.unique(data_strings[:,1]), np.unique(data_strings[:,1]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dec336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array listing all the status that are deemed as bad\n",
    "\n",
    "bad_status = np.array(['','Charged Off', 'Default', 'Late (31-120 days)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36680d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substitute 0 for all the locations where the loan status is bad and 1 for all other locations\n",
    "\n",
    "data_strings[:,1] = np.where(np.isin(data_strings[:,1], bad_status),0,1)\n",
    "\n",
    "\n",
    "# display all the unique values in the transformed loan_status column\n",
    "\n",
    "np.unique(data_strings[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4815c4",
   "metadata": {},
   "source": [
    "### Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a11fda01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '36 months', '60 months'], dtype='<U69')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the header name from term to term_months\n",
    "\n",
    "header_strings[2] = \"term_months\"\n",
    "\n",
    "\n",
    "# displaying the unique values in the term column\n",
    "np.unique(data_strings[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da055049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['36', '60'], dtype='<U69')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stripping the ' months' string from the term_months column to make it numeric\n",
    "\n",
    "data_strings[:,2] = np.chararray.strip(data_strings[:,2], \" months\")\n",
    "\n",
    "\n",
    "# replacing all nan columns with 60 months, as information not present equates to worst case scenario\n",
    "\n",
    "data_strings[:,2] = np.where(data_strings[:,2] == '',\n",
    "                            60,\n",
    "                            data_strings[:,2])\n",
    "\n",
    "\n",
    "# display all the unique values in the transformed term_months column\n",
    "\n",
    "np.unique(data_strings[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa127a",
   "metadata": {},
   "source": [
    "### Grade and Subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "554e3ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['', 'A', 'B', 'C', 'D', 'E', 'F', 'G'], dtype='<U69'),\n",
       " array(['', 'A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4',\n",
       "        'C5', 'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4',\n",
       "        'F5', 'G1', 'G2', 'G3', 'G4', 'G5'], dtype='<U69'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the unique values in grade and sub-grade column\n",
    "\n",
    "np.unique(data_strings[:,3]), np.unique(data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3ed30dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['A1', 'A2', 'A3', 'A4', 'A5', 'B1', 'B2', 'B3', 'B4', 'B5', 'C1', 'C2', 'C3', 'C4', 'C5',\n",
       "        'D1', 'D2', 'D3', 'D4', 'D5', 'E1', 'E2', 'E3', 'E4', 'E5', 'F1', 'F2', 'F3', 'F4', 'F5',\n",
       "        'G1', 'G2', 'G3', 'G4', 'G5', 'H1'], dtype='<U69'),\n",
       " array([285, 278, 239, 323, 592, 509, 517, 530, 553, 633, 629, 567, 586, 564, 577, 391, 267, 250,\n",
       "        255, 288, 235, 162, 171, 139, 160,  94,  52,  34,  43,  24,  19,  10,   3,   7,   5,   9],\n",
       "       dtype=int64))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning the lowest subgrade to the missing values where the grade is present\n",
    "\n",
    "for i in np.unique(data_strings[:,3])[1:]:\n",
    "    data_strings[:,4] = np.where((data_strings[:,4] == '') & (data_strings[:,3] == i),\n",
    "                                i + '5',\n",
    "                                data_strings[:,4])\n",
    "\n",
    "    \n",
    "# assigning a new subgrade to the values where both grades and subgrades are missing\n",
    "\n",
    "data_strings[:,4] = np.where(data_strings[:,4] == '',\n",
    "                            \"H1\",\n",
    "                            data_strings[:,4])\n",
    "\n",
    "\n",
    "# displaying the unique values in the transformed subgrade column\n",
    "np.unique(data_strings[:,4], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd930a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status', 'url',\n",
       "        'addr_state'], dtype='<U19'),\n",
       " array([['5', '1', '36', ..., 'Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=48010226', 'CA'],\n",
       "        ['0', '1', '36', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=57693261', 'NY'],\n",
       "        ['9', '1', '36', ..., 'Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=59432726', 'PA'],\n",
       "        ...,\n",
       "        ['6', '1', '36', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=50415990', 'CA'],\n",
       "        ['4', '1', '36', ..., 'Source Verified',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=46154151', 'OH'],\n",
       "        ['12', '1', '36', ..., '',\n",
       "         'https://www.lendingclub.com/browse/loanDetail.action?loan_id=66055249', 'IL']],\n",
       "       dtype='<U69'))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting the grade column in both string headers and data as the subgrade already holds the necessay information on the grades\n",
    "\n",
    "data_strings = np.delete(data_strings, 3, axis=1)\n",
    "\n",
    "header_strings = np.delete(header_strings, 3)\n",
    "\n",
    "\n",
    "# display the data_string and header_strings\n",
    "\n",
    "header_strings, data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d40f7d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A1': 1,\n",
       " 'A2': 2,\n",
       " 'A3': 3,\n",
       " 'A4': 4,\n",
       " 'A5': 5,\n",
       " 'B1': 6,\n",
       " 'B2': 7,\n",
       " 'B3': 8,\n",
       " 'B4': 9,\n",
       " 'B5': 10,\n",
       " 'C1': 11,\n",
       " 'C2': 12,\n",
       " 'C3': 13,\n",
       " 'C4': 14,\n",
       " 'C5': 15,\n",
       " 'D1': 16,\n",
       " 'D2': 17,\n",
       " 'D3': 18,\n",
       " 'D4': 19,\n",
       " 'D5': 20,\n",
       " 'E1': 21,\n",
       " 'E2': 22,\n",
       " 'E3': 23,\n",
       " 'E4': 24,\n",
       " 'E5': 25,\n",
       " 'F1': 26,\n",
       " 'F2': 27,\n",
       " 'F3': 28,\n",
       " 'F4': 29,\n",
       " 'F5': 30,\n",
       " 'G1': 31,\n",
       " 'G2': 32,\n",
       " 'G3': 33,\n",
       " 'G4': 34,\n",
       " 'G5': 35,\n",
       " 'H1': 36}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a dictionary is created to assign numeric values to the subgrades\n",
    "\n",
    "keys = list(np.unique(data_strings[:,3]))\n",
    "values = list(range(1, np.unique(data_strings[:,3]).shape[0] + 1))\n",
    "dict_subgrade = dict(zip(keys,values))\n",
    "\n",
    "\n",
    "# displaying the dictionary containing the subgrades and their assigned integers\n",
    "\n",
    "dict_subgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5ec7a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22',\n",
       "       '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '4', '5', '6', '7', '8', '9'], dtype='<U69')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning the respective numeric values to the subgrade column\n",
    "\n",
    "for i in np.unique(data_strings[:,3]):\n",
    "    data_strings[:,3] = np.where(data_strings[:,3] == i,\n",
    "                                dict_subgrade[i],\n",
    "                                data_strings[:,3])\n",
    "\n",
    "    \n",
    "# displaying the transformed subgrade column\n",
    "\n",
    "np.sort(np.unique(data_strings[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a2d68",
   "metadata": {},
   "source": [
    "### Verification Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f69e610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Not Verified', 'Source Verified', 'Verified'], dtype='<U69')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the unique values in the verification status table\n",
    "\n",
    "np.unique(data_strings[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98aa5c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1'], dtype='<U69')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning numeric values to the verification status table by classifying it under verified and not verifies status\n",
    "\n",
    "data_strings[:,4] = np.where((data_strings[:,4] =='') | (data_strings[:,4] == 'Not Verified'), 0, 1)\n",
    "\n",
    "\n",
    "# displaying the unique values in the transformed verification status table\n",
    "\n",
    "np.unique(data_strings[:,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9de55",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e778846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "        'addr_state'], dtype='<U19'),\n",
       " array([['5', '1', '36', '13', '1', 'CA'],\n",
       "        ['0', '1', '36', '5', '1', 'NY'],\n",
       "        ['9', '1', '36', '10', '1', 'PA'],\n",
       "        ...,\n",
       "        ['6', '1', '36', '5', '1', 'CA'],\n",
       "        ['4', '1', '36', '17', '1', 'OH'],\n",
       "        ['12', '1', '36', '4', '0', 'IL']], dtype='<U69'))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the url colum is not useful and the information it provides is already present in the id header\n",
    "# deleting the url column from the strings sub-dataset\n",
    "\n",
    "data_strings = np.delete(data_strings, 5, axis=1)\n",
    "\n",
    "\n",
    "# deleting the url header from the header array\n",
    "\n",
    "header_strings = np.delete(header_strings, 5)\n",
    "\n",
    "\n",
    "# display header_strings and data_strings\n",
    "\n",
    "header_strings, data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f967bc",
   "metadata": {},
   "source": [
    "### State Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab7510d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the header of the state address\n",
    "\n",
    "header_strings[5] = 'state_address'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c725eccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CA', 'NY', 'TX', 'FL', '', 'IL', 'NJ', 'GA', 'PA', 'OH', 'MI', 'NC', 'VA', 'MD', 'AZ',\n",
       "        'WA', 'MA', 'CO', 'MO', 'MN', 'IN', 'WI', 'CT', 'TN', 'NV', 'AL', 'LA', 'OR', 'SC', 'KY',\n",
       "        'KS', 'OK', 'UT', 'AR', 'MS', 'NH', 'NM', 'WV', 'HI', 'RI', 'MT', 'DE', 'DC', 'WY', 'AK',\n",
       "        'NE', 'SD', 'VT', 'ND', 'ME'], dtype='<U69'),\n",
       " array([1336,  777,  758,  690,  500,  389,  341,  321,  320,  312,  267,  261,  242,  222,  220,\n",
       "         216,  210,  201,  160,  156,  152,  148,  143,  143,  130,  119,  116,  108,  107,   84,\n",
       "          84,   83,   74,   74,   61,   58,   57,   49,   44,   40,   28,   27,   27,   27,   26,\n",
       "          25,   24,   17,   16,   10], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning the unique values of states and count to 2 variables\n",
    "\n",
    "state_names, states_count = np.unique(data_strings[:,5], return_counts=True)\n",
    "\n",
    "\n",
    "# sorting the states count and loading them as arguments to a variable\n",
    "\n",
    "states_count_sorted = np.argsort(-states_count)\n",
    "\n",
    "\n",
    "# displaying the states and states_count in the sorted order\n",
    "\n",
    "state_names[states_count_sorted], states_count[states_count_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "055ac07d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['5', '1', '36', '13', '1', 'CA'],\n",
       "       ['0', '1', '36', '5', '1', 'NY'],\n",
       "       ['9', '1', '36', '10', '1', 'PA'],\n",
       "       ...,\n",
       "       ['6', '1', '36', '5', '1', 'CA'],\n",
       "       ['4', '1', '36', '17', '1', 'OH'],\n",
       "       ['12', '1', '36', '4', '0', 'IL']], dtype='<U69')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning a value to the empty values in state address\n",
    "\n",
    "data_strings[:,5] = np.where(data_strings[:,5] == '',\n",
    "                            0,\n",
    "                            data_strings[:,5])\n",
    "\n",
    "# displaying the string dataset\n",
    "\n",
    "data_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aefa0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing the number of variables in the number of states by assigning the states to respective regions\n",
    "\n",
    "states_west = np.array(['WA', 'OR','CA','NV','ID','MT', 'WY','UT','CO', 'AZ','NM','HI','AK'])\n",
    "states_south = np.array(['TX','OK','AR','LA','MS','AL','TN','KY','FL','GA','SC','NC','VA','WV','MD','DE','DC'])\n",
    "states_midwest = np.array(['ND','SD','NE','KS','MN','IA','MO','WI','IL','IN','MI','OH'])\n",
    "states_east = np.array(['PA','NY','NJ','CT','MA','VT','NH','ME','RI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdae143c",
   "metadata": {},
   "source": [
    "**The above classification is done based on the proper documentation provided by the US government**\n",
    "\n",
    "https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca536a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4'], dtype='<U69')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assigning values to the state regions\n",
    "\n",
    "data_strings[:,5] = np.where(np.isin(data_strings[:,5], states_west), 1, data_strings[:,5])\n",
    "data_strings[:,5] = np.where(np.isin(data_strings[:,5], states_south), 2, data_strings[:,5])\n",
    "data_strings[:,5] = np.where(np.isin(data_strings[:,5], states_midwest), 3, data_strings[:,5])\n",
    "data_strings[:,5] = np.where(np.isin(data_strings[:,5], states_east), 4, data_strings[:,5])\n",
    "\n",
    "\n",
    "# displaying the unique values in the state address column\n",
    "\n",
    "np.unique(data_strings[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82419ea7",
   "metadata": {},
   "source": [
    "## Converting to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "19682d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  1, 36, 13,  1,  1],\n",
       "       [ 0,  1, 36,  5,  1,  4],\n",
       "       [ 9,  1, 36, 10,  1,  4],\n",
       "       ...,\n",
       "       [ 6,  1, 36,  5,  1,  1],\n",
       "       [ 4,  1, 36, 17,  1,  3],\n",
       "       [12,  1, 36,  4,  0,  3]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the string dataset to integers for easy analysis\n",
    "\n",
    "data_strings = data_strings.astype('int')\n",
    "\n",
    "\n",
    "# displaying the converted data_strings dataset\n",
    "\n",
    "data_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f8916a",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1efa30",
   "metadata": {},
   "source": [
    "### Checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76744737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a checkpoint for the transformed string variables\n",
    "\n",
    "checkpoint_strings = checkpoint(\"checkpoint-strings\",\n",
    "                               header_strings,\n",
    "                               data_strings)\n",
    "\n",
    "\n",
    "# checking if the data stored in the checkpoint is correct\n",
    "\n",
    "np.array_equal(checkpoint_strings['data'], data_strings), np.array_equal(checkpoint_strings['header'], header_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90392ee7",
   "metadata": {},
   "source": [
    "## Transforming the Numeric Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0513617f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt'], dtype='<U19'),\n",
       " array([[48010226,    35000,    35000,       13,     1184,     9452],\n",
       "        [57693261,    30000,    30000, 68616520,      938,     4679],\n",
       "        [59432726,    15000,    15000, 68616520,      494,     1969],\n",
       "        ...,\n",
       "        [50415990,    10000,    10000, 68616520, 68616520,     2185],\n",
       "        [46154151, 68616520,    10000,       16,      354,     3199],\n",
       "        [66055249,    10000,    10000, 68616520,      309,      301]]),\n",
       " 0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying the string headers and the string sub-dataset and checking for any nan values\n",
    "\n",
    "header_numeric, data_numeric, np.isnan(data_numeric).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58346034",
   "metadata": {},
   "source": [
    "### Sustitute \"Filler\" Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2692410",
   "metadata": {},
   "source": [
    "### ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f47d418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we must check if any of the values in the column are equal to the temporary fill\n",
    "\n",
    "np.isin(data_numeric[:,0], temp_fill).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1c860",
   "metadata": {},
   "source": [
    "#### Temporary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ee25abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     1000.  ,     1000.  ,        6.  ,       31.42,        0.  ],\n",
       "       [54015809.19,    15273.46,    15311.04,       16.62,      440.92,     3143.85],\n",
       "       [68616519.  ,    35000.  ,    35000.  ,       28.99,     1372.97,    41913.62]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the temporary stats customized for the numeric dataset\n",
    "# unlike series, arrays only take numerical indices\n",
    "\n",
    "temp_stats[:, column_numeric]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1534b7",
   "metadata": {},
   "source": [
    "### Funded Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c713b847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35000, 30000, 15000, ..., 10000, 10000, 10000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the funded amount is assigned min amount so that the risk of the loan is low\n",
    "\n",
    "data_numeric[:,2] = np.where(data_numeric[:,2] == temp_fill,\n",
    "                            temp_stats[0,column_numeric[2]],\n",
    "                            data_numeric[:,2])\n",
    "\n",
    "\n",
    "# displaying the funded amount column in the data_numeric array\n",
    "\n",
    "data_numeric[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e23280",
   "metadata": {},
   "source": [
    "### Loaned Amount, Interest Rate, Total Payment, Installment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b30ccd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48010226,    35000,    35000,       13,     1184,     9452],\n",
       "       [57693261,    30000,    30000,       28,      938,     4679],\n",
       "       [59432726,    15000,    15000,       28,      494,     1969],\n",
       "       ...,\n",
       "       [50415990,    10000,    10000,       28,     1372,     2185],\n",
       "       [46154151,    35000,    10000,       16,      354,     3199],\n",
       "       [66055249,    10000,    10000,       28,      309,      301]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these columns are assigned the max value for its missing values as it reduces the risk\n",
    "\n",
    "for i in [1,3,4,5]:\n",
    "    data_numeric[:,i] = np.where(data_numeric[:,i] == temp_fill,\n",
    "                                temp_stats[2, column_numeric[i]],\n",
    "                                data_numeric[:,i])\n",
    "    \n",
    "    \n",
    "# displaying the data_numeric dataset\n",
    "\n",
    "data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a15136",
   "metadata": {},
   "source": [
    "## Changing the currency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356f1c6",
   "metadata": {},
   "source": [
    "### The Exchange Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0ccd492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13, 1.12, 1.08, 1.11, 1.1 , 1.12, 1.09, 1.13, 1.13, 1.1 , 1.06, 1.09])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the csv file containing the exchange rates across the months for the year 2015\n",
    "\n",
    "eur_usd = np.genfromtxt(\"EUR-USD.csv\",\n",
    "                        delimiter=',',\n",
    "                        autostrip=True,\n",
    "                        skip_header=1,\n",
    "                        usecols=3)\n",
    "\n",
    "\n",
    "# displaying the imported dataset containing the exchange rate\n",
    "\n",
    "eur_usd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e530024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new array that is the copy of the issue date of the loan\n",
    "\n",
    "exchange_rate = data_strings[:,0]\n",
    "\n",
    "\n",
    "# exchange rates for the respective months are assigned in the place of the months\n",
    "\n",
    "for i in range(1, 13):\n",
    "    exchange_rate = np.where(exchange_rate == i,\n",
    "                            eur_usd[i-1],\n",
    "                            exchange_rate)\n",
    "\n",
    "\n",
    "# for loan where the issue date was unknown, the mean of the exchange rate for the year was assigned\n",
    "\n",
    "exchange_rate = np.where(exchange_rate == 0,\n",
    "                        np.mean(eur_usd),\n",
    "                        exchange_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f80817",
   "metadata": {},
   "source": [
    "### Reshaping the exchange rate array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5b9bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 6))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the shapes of exchange_rate and data_numeric array for future appending\n",
    "\n",
    "exchange_rate.shape, data_numeric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cecb8aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping the exchange_rate array\n",
    "\n",
    "exchange_rate = np.reshape(exchange_rate, (10000,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3686f6b",
   "metadata": {},
   "source": [
    "### Concartenating two arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5567188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt', 'funded_amnt', 'int_rate', 'installment', 'total_pymnt', 'exchange_rate'],\n",
       "       dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    35000.  , ...,     1184.  ,     9452.  ,        1.1 ],\n",
       "        [57693261.  ,    30000.  ,    30000.  , ...,      938.  ,     4679.  ,        1.11],\n",
       "        [59432726.  ,    15000.  ,    15000.  , ...,      494.  ,     1969.  ,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,    10000.  , ...,     1372.  ,     2185.  ,        1.12],\n",
       "        [46154151.  ,    35000.  ,    10000.  , ...,      354.  ,     3199.  ,        1.11],\n",
       "        [66055249.  ,    10000.  ,    10000.  , ...,      309.  ,      301.  ,        1.09]]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending the exchange_rate array horizontally to the data_numeric array\n",
    "\n",
    "data_numeric = np.hstack((data_numeric, exchange_rate))\n",
    "\n",
    "\n",
    "# adding a new header to the header_numeric\n",
    "\n",
    "header_numeric = np.concatenate((header_numeric, np.array(['exchange_rate'])))\n",
    "\n",
    "\n",
    "# displaying the data_numeric and header_numeric arrays\n",
    "\n",
    "header_numeric, data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919cec2b",
   "metadata": {},
   "source": [
    "### From USD to EUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "542a3ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt_USD', 'loan_amnt_eur', 'funded_amnt_USD', 'funded_amnt_eur', 'int_rate',\n",
       "        'installment_USD', 'installment_eur', 'total_pymnt_USD', 'total_pymnt_eur', 'exchange_rate'],\n",
       "       dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    31933.3 , ...,     9452.  ,     8623.82,        1.1 ],\n",
       "        [57693261.  ,    30000.  ,    27132.46, ...,     4679.  ,     4231.76,        1.11],\n",
       "        [59432726.  ,    15000.  ,    13326.3 , ...,     1969.  ,     1749.3 ,        1.13],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,     8910.3 , ...,     2185.  ,     1946.9 ,        1.12],\n",
       "        [46154151.  ,    35000.  ,    31490.9 , ...,     3199.  ,     2878.27,        1.11],\n",
       "        [66055249.  ,    10000.  ,     9145.8 , ...,      301.  ,      275.29,        1.09]]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining an array containing the addresses of the columns in data_numeric that need to be changed\n",
    "\n",
    "column_dollar = np.array([1,2,4,5])\n",
    "\n",
    "\n",
    "# creating and appending new columns that are in euros\n",
    "\n",
    "for i in column_dollar:\n",
    "    data_numeric = np.hstack((data_numeric, \n",
    "                              np.reshape(data_numeric[:,i] / data_numeric[:,6],\n",
    "                                        (10000,1))))\n",
    "    \n",
    "\n",
    "# creating new headers and appending them to header_numeric\n",
    "\n",
    "header_numeric = np.concatenate((header_numeric, \n",
    "                                 np.array([i + '_eur' for i in header_numeric[column_dollar]])))\n",
    "\n",
    "\n",
    "# renaming the existing headers\n",
    "\n",
    "header_numeric[column_dollar] = np.array([i + '_USD' for i in header_numeric[column_dollar]])\n",
    "\n",
    "\n",
    "# rearranging the headers and the data columns to make it more sensible\n",
    "\n",
    "column_numeric_order = [0,1,7,2,8,3,4,9,5,10,6]\n",
    "\n",
    "header_numeric = header_numeric[column_numeric_order]\n",
    "\n",
    "data_numeric = data_numeric[:, column_numeric_order]\n",
    "\n",
    "\n",
    "# display the header_numeric and data_numeric tables\n",
    "\n",
    "header_numeric, data_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445dc5d6",
   "metadata": {},
   "source": [
    "### Interest Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4617ddaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.28, 0.28, ..., 0.28, 0.16, 0.28])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convering the interest rate form percentage form to probability form for easy calculation\n",
    "\n",
    "data_numeric[:,5] = data_numeric[:, 5] / 100\n",
    "\n",
    "\n",
    "# display the interest rate row in the data_numeric column\n",
    "data_numeric[:,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0470c092",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f07fc04",
   "metadata": {},
   "source": [
    "### Checkpoint 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf641b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a checkpoint for the transformed numeric variables\n",
    "\n",
    "checkpoint_numeric = checkpoint(\"checkpoint-numeric\",\n",
    "                               header_numeric,\n",
    "                               data_numeric)\n",
    "\n",
    "\n",
    "# checking if the data stored in the checkpoint is correct\n",
    "\n",
    "np.array_equal(checkpoint_numeric['data'], data_numeric), np.array_equal(checkpoint_numeric['header'], header_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf79b17",
   "metadata": {},
   "source": [
    "## Creating the \"Complete\" Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02492d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['id', 'loan_amnt_USD', 'loan_amnt_eur', 'funded_amnt_USD', 'funded_amnt_eur', 'int_rate',\n",
       "        'installment_USD', 'installment_eur', 'total_pymnt_USD', 'total_pymnt_eur', 'exchange_rate',\n",
       "        'issue_date', 'loan_status', 'term_months', 'sub_grade', 'verification_status',\n",
       "        'state_address'], dtype='<U19'),\n",
       " array([[48010226.  ,    35000.  ,    31933.3 , ...,       13.  ,        1.  ,        1.  ],\n",
       "        [57693261.  ,    30000.  ,    27132.46, ...,        5.  ,        1.  ,        4.  ],\n",
       "        [59432726.  ,    15000.  ,    13326.3 , ...,       10.  ,        1.  ,        4.  ],\n",
       "        ...,\n",
       "        [50415990.  ,    10000.  ,     8910.3 , ...,        5.  ,        1.  ,        1.  ],\n",
       "        [46154151.  ,    35000.  ,    31490.9 , ...,       17.  ,        1.  ,        3.  ],\n",
       "        [66055249.  ,    10000.  ,     9145.8 , ...,        4.  ,        0.  ,        3.  ]]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating the numeric and string data arrays\n",
    "\n",
    "loan_data = np.hstack((checkpoint_numeric['data'], checkpoint_strings['data']))\n",
    "\n",
    "\n",
    "# concatenating the numeric and string header arrays\n",
    "\n",
    "loan_header = np.concatenate((checkpoint_numeric['header'], checkpoint_strings['header']))\n",
    "\n",
    "\n",
    "# displaying the concatenated header and data\n",
    "\n",
    "loan_header, loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e9f8c6",
   "metadata": {},
   "source": [
    "## Sorting the New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a614fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  373332.  ,     9950.  ,     9038.08, ...,       21.  ,        0.  ,        1.  ],\n",
       "       [  575239.  ,    12000.  ,    10900.2 , ...,       25.  ,        1.  ,        2.  ],\n",
       "       [  707689.  ,    10000.  ,     8924.3 , ...,       13.  ,        1.  ,        0.  ],\n",
       "       ...,\n",
       "       [68614880.  ,     5600.  ,     5121.65, ...,        8.  ,        1.  ,        1.  ],\n",
       "       [68615915.  ,     4000.  ,     3658.32, ...,       10.  ,        1.  ,        2.  ],\n",
       "       [68616519.  ,    21600.  ,    19754.93, ...,        3.  ,        0.  ,        2.  ]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting the entire dataset based on the ID column in ascending order\n",
    "\n",
    "loan_data = loan_data[np.argsort(loan_data[:,0])]\n",
    "\n",
    "\n",
    "# displaying the transformed dataset\n",
    "\n",
    "loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6d11c",
   "metadata": {},
   "source": [
    "## Storing the New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2d3ef2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating the header and data of the complete dataset\n",
    "\n",
    "loan_data = np.vstack((loan_header, loan_data))\n",
    "\n",
    "\n",
    "# save the dataset in the form of a csv\n",
    "\n",
    "np.savetxt(\"loan-data-preprpcessed.csv\",\n",
    "          loan_data,\n",
    "          fmt='%s',\n",
    "          delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
